"""empty message

Revision ID: 1d1657dfe734
Revises: baseline
Create Date: 2025-11-17 15:30:24.958840

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '1d1657dfe734'
down_revision = 'baseline'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('segment', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_segment_dataset_id'))
        batch_op.drop_index(batch_op.f('idx_segment_document_id'))

    op.drop_table('segment')
    with op.batch_alter_table('document', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_document_dataset_id'))

    op.drop_table('document')
    op.drop_table('conversation')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('conversation',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('uid', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('messages', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('conversation_pkey'))
    )
    op.create_table('document',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('dataset_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('file_name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('file_path', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('status', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('document_pkey'))
    )
    with op.batch_alter_table('document', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_document_dataset_id'), ['dataset_id'], unique=False)

    op.create_table('segment',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('dataset_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('document_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('order', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('content', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('status', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('segment_pkey'))
    )
    with op.batch_alter_table('segment', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_segment_document_id'), ['document_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_segment_dataset_id'), ['dataset_id'], unique=False)

    # ### end Alembic commands ###
